name: Daily Recipe Scraper

on:
  schedule:
    # Runs at 2 AM UTC every day
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger from GitHub UI

jobs:
  scrape-and-embed:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install requests psycopg2-binary google-generativeai python-dotenv

      - name: Scrape recipes from free APIs
        env:
          SUPABASE_DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
          SPOONACULAR_API_KEY: ${{ secrets.SPOONACULAR_API_KEY }}
        run: |
          echo "üîç Scraping recipes from TheMealDB and Spoonacular..."
          python scripts/scrape_recipes.py --count 50

      - name: Generate embeddings for new recipes
        env:
          SUPABASE_DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          echo "üß† Generating embeddings with Gemini..."
          python scripts/generate_embeddings.py

      - name: Report statistics
        if: always()
        env:
          SUPABASE_DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
        run: |
          python -c "import os; import psycopg2; conn = psycopg2.connect(os.getenv('SUPABASE_DATABASE_URL')); cur = conn.cursor(); cur.execute('SELECT COUNT(*) FROM recipes'); recipe_count = cur.fetchone()[0]; cur.execute('SELECT COUNT(*) FROM recipe_embeddings'); embedding_count = cur.fetchone()[0]; print(f'‚úÖ Scraping completed! Database now has {recipe_count} recipes, {embedding_count} embeddings')"
