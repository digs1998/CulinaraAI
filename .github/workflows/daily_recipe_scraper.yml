name: Daily Recipe Scraper

on:
  schedule:
    # Runs at 6 AM UTC every day (12 AM CST)
    - cron: '0 6 * * *'
  workflow_dispatch: # Allow manual trigger from GitHub UI

jobs:
  scrape-and-embed:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install requests psycopg2-binary google-generativeai python-dotenv

      - name: Scrape recipes from free APIs
        env:
          SUPABASE_DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
          EDAMAM_APP_ID: ${{ secrets.EDAMAM_APP_ID }}
          EDAMAM_APP_KEY: ${{ secrets.EDAMAM_APP_KEY }}
          RAPIDAPI_KEY: ${{ secrets.RAPIDAPI_KEY }}
          SPOONACULAR_API_KEY: ${{ secrets.SPOONACULAR_API_KEY }}
        run: |
          python scripts/scrape_recipes.py

      - name: Generate embeddings for new recipes
        env:
          SUPABASE_DATABASE_URL: ${{ secrets.SUPABASE_DATABASE_URL }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          python scripts/generate_embeddings.py

      - name: Report status
        if: always()
        run: |
          if [ $? -eq 0 ]; then
            echo "✅ Recipe scraping completed successfully"
          else
            echo "❌ Recipe scraping failed - check logs"
            exit 1
          fi
